import os
from dotenv import load_dotenv

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
# app.py
# -----------------------------------------
# å˜ä¸€å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ  + ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶A/Bã‚’åˆ‡æ›¿
# LangChainçµŒç”±ã§LLMã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ¸¡ã—ã€å›ç­”ã‚’è¡¨ç¤ºã™ã‚‹Streamlitã‚¢ãƒ—ãƒª
# Lesson8ã‚¹ã‚¿ã‚¤ãƒ«: PromptTemplate -> LLM -> OutputParser ã®ãƒã‚§ãƒ¼ãƒ³
# -----------------------------------------

import streamlit as st

# LangChain (OpenAI) - Lesson8ç›¸å½“ã®åŸºæœ¬æ§‹æˆ
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser


# ====== è¨­å®š ======
# ãƒ»ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‚’ã‚»ãƒƒãƒˆã—ã¦ã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„
#   macOS/Linux:  export OPENAI_API_KEY="sk-xxxx"
#   Windows(PowerShell):  setx OPENAI_API_KEY "sk-xxxx"  (å†èµ·å‹•å¾Œã«æœ‰åŠ¹)
#
# ãƒ»ãƒ¢ãƒ‡ãƒ«ã¯å¿…è¦ã«å¿œã˜ã¦å¤‰æ›´å¯ï¼ˆä¾‹: "gpt-4o-mini" / "gpt-4.1-mini" ãªã©ï¼‰
MODEL_NAME = "gpt-4o-mini"
TEMPERATURE = 0.2


# ====== LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ ======
llm = ChatOpenAI(model=MODEL_NAME, temperature=TEMPERATURE)


# ====== å°‚é–€å®¶ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆA/Bã§åˆ‡æ›¿ï¼‰ ======
# ã“ã“ã¯ãŠå¥½ã¿ã§å¢—æ¸›ãƒ»èª¿æ•´OK
EXPERT_SYSTEM_PROMPTS = {
    # A: å»ºè¨­DXãƒ»ç¾å ´æœ€é©åŒ–ã®å°‚é–€å®¶ï¼ˆãŸã‹ã•ã‚“ã«åˆã‚ã›ã¦Aã¯å»ºè¨­å¯„ã‚Šã«ï¼ï¼‰
    "Aï¼ˆå»ºè¨­DXã‚³ãƒ³ã‚µãƒ«ï¼‰": """ã‚ãªãŸã¯å»ºè¨­DXã¨æ–½å·¥ç®¡ç†ã®å°‚é–€å®¶ã§ã™ã€‚
ç¾å ´å®‰å…¨ãƒ»å·¥ç¨‹ç®¡ç†ãƒ»åŸä¾¡ä½æ¸›ãƒ»ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³ãƒ»AI/ãƒ‡ãƒ¼ã‚¿æ´»ç”¨ã«ç²¾é€šã—ã¦ã„ã¾ã™ã€‚
å›ç­”ã¯ã€Œçµè«– â†’ æ‰‹é † â†’ ãƒ„ãƒ¼ãƒ«ä¾‹ â†’ ãƒªã‚¹ã‚¯/æ³¨æ„ç‚¹ â†’ æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ã®é †ã§ã€ç¾å ´ã§ã™ãä½¿ãˆã‚‹å®Ÿå‹™ãƒ¬ãƒ™ãƒ«ã§ç°¡æ½”ã«ææ¡ˆã—ã¦ãã ã•ã„ã€‚
å°‚é–€ç”¨èªã¯çŸ­ãè£œè¶³ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚""",

    # B: TikTokã‚°ãƒ­ãƒ¼ã‚¹ã®å°‚é–€å®¶ï¼ˆå…ˆè¼©ã®äº‹æ¥­ã«ãƒ‰ãƒ³ãƒ”ã‚·ãƒ£ãªã‚‚ã†ä¸€æ ï¼‰
    "Bï¼ˆTikTokã‚°ãƒ­ãƒ¼ã‚¹ï¼‰": """ã‚ãªãŸã¯TikTokã®ã‚°ãƒ­ãƒ¼ã‚¹ãƒãƒƒã‚«ãƒ¼ã§ã€è¦–è´ç¶­æŒã¨ãƒ•ã‚©ãƒ­ãƒ¼ç²å¾—ã«ç‰¹åŒ–ã—ãŸå°‚é–€å®¶ã§ã™ã€‚
è¡Œå‹•çµŒæ¸ˆå­¦ï¼ˆãƒ—ãƒ­ã‚¹ãƒšã‚¯ãƒˆç†è«–ï¼‰ãƒ»ã‚«ãƒªã‚®ãƒ¥ãƒ©åŠ¹æœãƒ»3ç§’ãƒ•ãƒƒã‚¯ãƒ»CTAè¨­è¨ˆãƒ»A/Bãƒ†ã‚¹ãƒˆã«ç²¾é€šã—ã¦ã„ã¾ã™ã€‚
å›ç­”ã¯ã€Œçµè«– â†’ 30ç§’å°æœ¬ä¾‹ â†’ ãƒ•ãƒƒã‚¯/CTAæ¡ˆ â†’ ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°æ–¹é‡ â†’ è¨ˆæ¸¬/KPI â†’ æ˜æ—¥ã‚„ã‚‹ã“ã¨ã€ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
å°‚é–€ç”¨èªã¯çŸ­ãè£œè¶³ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚"""
}


# ====== ã‚³ã‚¢é–¢æ•°ï¼ˆæŒ‡å®šï¼šå¼•æ•°=å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆï¼†é¸æŠå€¤ / æˆ»ã‚Šå€¤=LLMå›ç­”ï¼‰ ======
def ask_expert(input_text: str, expert_choice: str) -> str:
    """
    å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨å°‚é–€å®¶é¸æŠå€¤ï¼ˆãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®å€¤ï¼‰ã‚’å—ã‘å–ã‚Šã€
    å°‚é–€å®¶ã«å¿œã˜ãŸSystemãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§LLMã¸æŠ•ã’ã€æ–‡å­—åˆ—ã¨ã—ã¦å›ç­”ã‚’è¿”ã™ã€‚
    """
    if not input_text or not input_text.strip():
        return "å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™ã€‚å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"

    system_message = EXPERT_SYSTEM_PROMPTS.get(
        expert_choice,
        "ã‚ãªãŸã¯æœ‰èƒ½ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç›®çš„é”æˆã‚’æœ€çŸ­ã§æ”¯æ´ã—ã¦ãã ã•ã„ã€‚"
    )

    # Lesson8ã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒã‚§ãƒ¼ãƒ³: PromptTemplate -> LLM -> StrOutputParser
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_message),
        ("human", "{user_input}")
    ])

    chain = prompt | llm | StrOutputParser()
    return chain.invoke({"user_input": input_text})


# ====== Streamlit UI ======
st.set_page_config(page_title="Lesson8é¢¨ï¼šå°‚é–€å®¶åˆ‡æ›¿ãƒãƒ£ãƒƒãƒˆ", page_icon="ğŸ› ï¸", layout="centered")

st.title("ğŸ› ï¸ Lesson8é¢¨ï¼šå°‚é–€å®¶A/Bã‚’åˆ‡ã‚Šæ›¿ãˆã¦è³ªå•")
st.caption("Powered by LangChain + OpenAI")

with st.expander("ğŸ“˜ ã“ã®Webã‚¢ãƒ—ãƒªã®æ¦‚è¦ã¨ä½¿ã„æ–¹", expanded=True):
    st.markdown(
        """
**ã§ãã‚‹ã“ã¨**  
- å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’1ã¤å…¥ã‚Œã¦é€ä¿¡ã™ã‚‹ã¨ã€LangChainçµŒç”±ã§LLMã«æŠ•ã’ã¦å›ç­”ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚  
- ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§ã€ŒAï¼ˆå»ºè¨­DXã‚³ãƒ³ã‚µãƒ«ï¼‰ã€ã‹ã€ŒBï¼ˆTikTokã‚°ãƒ­ãƒ¼ã‚¹ï¼‰ã€ã‚’é¸ã¶ã¨ã€  
  ãã‚Œãã‚Œã®å°‚é–€å®¶ã¨ã—ã¦ã® **ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸** ãŒæŒ¿ã—æ›¿ã‚ã‚Šã€å›ç­”ã®åˆ‡ã‚Šå£ãŒå¤‰ã‚ã‚Šã¾ã™ã€‚

**ä½¿ã„æ–¹**  
1. ç”»é¢ä¸‹ã®ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶ã‚’é¸ã¶  
2. å…¥åŠ›ãƒœãƒƒã‚¯ã‚¹ã«è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’æ›¸ãï¼ˆä¾‹ï¼šã€Œç¾å ´ã®å®‰å…¨ç‚¹æ¤œã‚’åŠ¹ç‡åŒ–ã—ãŸã„ã€ã‚„ã€Œãƒ•ã‚©ãƒ­ãƒ¼ãŒä¼¸ã³ãªã„ã€ï¼‰  
3. **é€ä¿¡** ã‚’æŠ¼ã™ã¨ã€å›ç­”ãŒä¸‹ã«è¡¨ç¤ºã•ã‚Œã¾ã™

**ç’°å¢ƒæº–å‚™**  
- äº‹å‰ã« `OPENAI_API_KEY` ã‚’ç’°å¢ƒå¤‰æ•°ã§è¨­å®šã—ã¦ãã ã•ã„  
- å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ã®ä¾‹ï¼š  
  - `pip install streamlit langchain langchain-openai`  
  - `streamlit run app.py`
        """
    )

with st.form("qa_form"):
    expert = st.radio(
        "å°‚é–€å®¶ã‚’é¸æŠï¼š",
        options=list(EXPERT_SYSTEM_PROMPTS.keys()),
        horizontal=True
    )
    user_text = st.text_area(
        "å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ",
        placeholder="ä¾‹ï¼‰å·¥ç¨‹é…å»¶ã‚’æœ€å°åŒ–ã™ã‚‹ç¾å ´é‹ç”¨ã®å‹ã‚’ä½œã‚ŠãŸã„ï¼3ç§’ã§æ´ã‚€ãƒ•ãƒƒã‚¯æ¡ˆã‚’å¢—ã‚„ã—ãŸã„ ãªã©",
        height=140
    )
    submitted = st.form_submit_button("é€ä¿¡ã™ã‚‹ ğŸš€")

if submitted:
    with st.spinner("å°‚é–€å®¶ãŒè€ƒãˆä¸­â€¦"):
        try:
            answer = ask_expert(user_text, expert)
            st.success("å›ç­”ãŒå±Šãã¾ã—ãŸ")
            st.markdown("### âœï¸ å›ç­”")
            st.write(answer)
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š{e}")

    with st.expander("ğŸ”§ ç¾åœ¨ã®å°‚é–€å®¶ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆSystemãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰ã‚’ç¢ºèªã™ã‚‹"):
        st.code(EXPERT_SYSTEM_PROMPTS.get(expert, ""), language="markdown")
